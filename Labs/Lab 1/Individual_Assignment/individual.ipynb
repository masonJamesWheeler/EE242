{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as sig\n",
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions developed in the lab\n",
    "\n",
    "def timescale(x, fs, a):\n",
    "    #n, d = decimal.Decimal(a).as_integer_ratio()\n",
    "    [n, d] = (np.double(a)).as_integer_ratio()\n",
    "    y = sig.resample_poly(x,d,n)\n",
    "    t = np.arange(0,len(y),1)*(1.0/fs)\n",
    "    return y,t\n",
    "\n",
    "def play_audio(file_name):\n",
    "    fs, audio_data = wav.read(file_name)\n",
    "    play_obj = sa.play_buffer(audio_data, audio_data.ndim, 2, fs)\n",
    "    play_obj.wait_done()\n",
    "\n",
    "def timeshift(x, fs, t0):\n",
    "    n0 = int(fs * t0)\n",
    "    \n",
    "    if t0 > 0:  # time delay\n",
    "        y = np.concatenate((np.zeros(n0), x))\n",
    "    else:  # time advance\n",
    "        y = np.concatenate((x[-n0:], np.zeros(-n0)))\n",
    "    \n",
    "    t = np.arange(0, len(y), 1) * (1.0 / fs)\n",
    "    return y, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(audio):\n",
    "    audio = audio.astype(np.float32)\n",
    "    audio /= np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "# Load two sounds (either provided, from an open repository, or your own collection)\n",
    "fs1, x1 = wav.read('tuba11.wav')\n",
    "fs2, x2 = wav.read('flute11.wav')\n",
    "\n",
    "# If the sounds have 2 channels, extract audio data from only one channel\n",
    "if x1.ndim > 1:\n",
    "    x1 = x1[:, 0]\n",
    "if x2.ndim > 1:\n",
    "    x2 = x2[:, 0]\n",
    "\n",
    "# Normalize the audio signals\n",
    "x1 = normalize_audio(x1)\n",
    "x2 = normalize_audio(x2)\n",
    "\n",
    "# Time scaling\n",
    "a = 0.5\n",
    "scaled_x1, _ = timescale(x1, fs1, a)\n",
    "\n",
    "# Time shifting\n",
    "shifted_x2, _ = timeshift(x2, fs2, 1.0)  # Shift by 1 second\n",
    "\n",
    "# Pad the shorter signal with zeros to make them the same length\n",
    "len_diff = abs(len(scaled_x1) - len(shifted_x2))\n",
    "if len(scaled_x1) > len(shifted_x2):\n",
    "    shifted_x2 = np.concatenate((shifted_x2, np.zeros(len_diff)))\n",
    "else:\n",
    "    scaled_x1 = np.concatenate((scaled_x1, np.zeros(len_diff)))\n",
    "\n",
    "# Addition (scale the result by 0.5 to avoid clipping)\n",
    "added_signals = 0.5 * (scaled_x1 + shifted_x2)\n",
    "\n",
    "# Multiplication\n",
    "multiplied_signals = scaled_x1 * shifted_x2\n",
    "\n",
    "# Concatenate sounds with a brief silence (vector of zeros)\n",
    "silence = np.zeros(int(fs1 * 0.5))  # 0.5-second silence\n",
    "concatenated_signals = np.concatenate((multiplied_signals, silence, added_signals))\n",
    "\n",
    "# Save the new signal to a WAV file (no more than 20 seconds in length)\n",
    "wav.write('new_signal.wav', fs1, (concatenated_signals * 32767).astype(np.int16))\n",
    "\n",
    "# Play the new signal\n",
    "play_audio('new_signal.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
